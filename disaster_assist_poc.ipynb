{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0f0fefc",
   "metadata": {},
   "source": [
    "# Disaster Assist Scraping\n",
    "- This script utilises Edge browser and Selenium, ensure you have web driver - https://developer.microsoft.com/en-us/microsoft-edge/tools/webdriver/\n",
    "- POC scrape data associated with this page: https://www.disasterassist.gov.au/find-a-disaster/australian-disasters and follow the link to the next page to get LGA names\n",
    "\n",
    "The script would benefit from being more modular, however is POC currently and needs to be tested to ensure it works\n",
    "\n",
    "The script also needs to add a pause when interactive with page to avoid issues\n",
    "\n",
    "Bug in step 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a69201ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Import packages\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime, timedelta, date\n",
    "import getpass\n",
    "import pandas as pd\n",
    "import requests\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Note you will need to chnage edge driver based on where you have it saved\n",
    "edge_driver_path = r'C:\\webdrivers\\msedgedriver.exe'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d2a613",
   "metadata": {},
   "source": [
    "## Interact wit dynamic page\n",
    "The code below utilise Edge driver to extract URLs from Disaster Assist, this script is only concered with URLs from 2023 onwards currently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d5fa1fe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://www.disasterassist.gov.au/Pages/disasters/current-disasters/New-South-Wales/bega-valley-bushfires-3-october-2023-onwards.aspx', 'https://www.disasterassist.gov.au/Pages/disasters/current-disasters/Victoria/south-east-victorian-storms-8-september-2023.aspx', 'https://www.disasterassist.gov.au/Pages/disasters/current-disasters/Northern-Territory/barkly-region-bushfire-september-2023.aspx', 'https://www.disasterassist.gov.au/Pages/disasters/current-disasters/New-South-Wales/north-eastern-nsw-bushfires-21-august-2023-onwards.aspx', 'https://www.disasterassist.gov.au/Pages/disasters/current-disasters/Victoria/north-victorian-storms-commencing-7-june-2023.aspx', 'https://www.disasterassist.gov.au/Pages/disasters/current-disasters/Queensland/southwest-queensland-flooding-4-June-15-June-2023.aspx', 'https://www.disasterassist.gov.au/Pages/disasters/current-disasters/Northern-Territory/east-arnhem-region-flooding-16-18-april-2023.aspx', 'https://www.disasterassist.gov.au/Pages/disasters/current-disasters/Western-Australia/tropical-cyclone-ilsa-13-april-2023-onwards.aspx', 'https://www.disasterassist.gov.au/Pages/disasters/current-disasters/Western-Australia/midwest-gascoyne-pilbara-storms-associated-flooding.aspx', 'https://www.disasterassist.gov.au/Pages/disasters/current-disasters/Western-Australia/wheatbelt-region-wa-storm-flooding-25-26-march-2023.aspx', 'https://www.disasterassist.gov.au/Pages/disasters/current-disasters/Victoria/north-east-vic-storms-march-2023.aspx', 'https://www.disasterassist.gov.au/Pages/disasters/current-disasters/New-South-Wales/upper-lachlan-bushfires-from-16-march-2023.aspx', 'https://www.disasterassist.gov.au/Pages/disasters/current-disasters/New-South-Wales/cootamundra-gundagai-hilltops-storm-flooding-12-march-2023.aspx', 'https://www.disasterassist.gov.au/Pages/disasters/current-disasters/New-South-Wales/nsw-bushfires-march-2023.aspx', 'https://www.disasterassist.gov.au/Pages/disasters/current-disasters/New-South-Wales/gwydir-moree-plains-and-narrabri-bushfires-nsw-from-1-march-2023.aspx', 'https://www.disasterassist.gov.au/Pages/disasters/current-disasters/Northern-Territory/northern-region-flooding-february-2023.aspx', 'https://www.disasterassist.gov.au/Pages/disasters/current-disasters/New-South-Wales/western-and-north-west-nsw-bushfires-17-february-2023.aspx', 'https://www.disasterassist.gov.au/Pages/disasters/current-disasters/New-South-Wales/upper-lachlan-yass-valley-nsw-bushfires-11-february-2023.aspx', 'https://www.disasterassist.gov.au/Pages/disasters/current-disasters/New-South-Wales/nsw-severe-storms-9-february-2023.aspx', 'https://www.disasterassist.gov.au/Pages/disasters/current-disasters/New-South-Wales/port-macquarie-hastings-severe-storm-3-february-2023.aspx', 'https://www.disasterassist.gov.au/Pages/disasters/current-disasters/Queensland/western-downs-bushfires-30-january-onwards.aspx', 'https://www.disasterassist.gov.au/Pages/disasters/current-disasters/New-South-Wales/cootamundra-gundagai-bushfires-25-january-2023.aspx', 'https://www.disasterassist.gov.au/Pages/disasters/current-disasters/New-South-Wales/gwydir-and-narrabri-nsw-bushfires-1-march-2023.aspx', 'https://www.disasterassist.gov.au/Pages/disasters/current-disasters/Victoria/benalla-tornado-14-january-2023.aspx']\n"
     ]
    }
   ],
   "source": [
    "# Step 2\n",
    "\n",
    "# Initialize the Edge driver\n",
    "driver = webdriver.Edge(executable_path=edge_driver_path)\n",
    "\n",
    "# URL of the website\n",
    "base_url = 'https://www.disasterassist.gov.au/find-a-disaster/australian-disasters'\n",
    "\n",
    "# Open the website\n",
    "driver.get(base_url)\n",
    "\n",
    "# Extract and print URLs for the year 2023\n",
    "urls = []\n",
    "while True:\n",
    "    table_rows = driver.find_elements(By.CLASS_NAME, 'desk-result')\n",
    "    for row in table_rows:\n",
    "        # Extract start date and check if the year is 2023\n",
    "        start_date = row.find_elements(By.TAG_NAME, 'td')[0].text\n",
    "        if \"2023\" in start_date:\n",
    "            urls.append(row.find_element(By.TAG_NAME, 'a').get_attribute('href'))\n",
    "        else:\n",
    "            # If the year is not 2023, break the loop\n",
    "            break\n",
    "    try:\n",
    "        # Locate the next page button\n",
    "        next_button = driver.find_element(By.ID, 'btnNext')\n",
    "        \n",
    "        # Scroll the button into view\n",
    "        driver.execute_script(\"arguments[0].scrollIntoView(true);\", next_button)\n",
    "        \n",
    "        # Click the next button\n",
    "        next_button.click()\n",
    "    except:\n",
    "        # If there is no next button, break the loop\n",
    "        break\n",
    "\n",
    "# Close the browser window\n",
    "driver.quit()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d42e4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d685e8fd",
   "metadata": {},
   "source": [
    "## Extract AGRN and LGA names of public anounced disasters\n",
    "Looping through the URLs we are able to get AGRN and LGA list returned into pandas df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f4b062",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Step 3\n",
    "\n",
    "data_list = []\n",
    "\n",
    "for url in urls:\n",
    "    # Get the current date and time\n",
    "    extraction_date = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    \n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    # Extract relevant information from soup object\n",
    "    # Modify the code below to extract the specific information you need from the URL pages\n",
    "    agrn = soup.find('div', id='AGRN').text.strip()\n",
    "\n",
    "    # Extract location names from <ul> and <li> elements\n",
    "    location_container = soup.find('div', {'id': 'LGA'})\n",
    "    # Extract location names from <ul> and <li> elements\n",
    "    location_elements = soup.find('div', id='LGA').find_all('a')\n",
    "    locations = ', '.join([location.text.strip() for location in location_elements])\n",
    "    \n",
    "    \n",
    "    data_dict = {\n",
    "        \"agrn\": agrn,\n",
    "        'lga': locations,\n",
    "        'extraction_date': extraction_date\n",
    "    }\n",
    "        \n",
    "    \n",
    "    # Append the dictionary to the data_list\n",
    "    data_list.append(data_dict)\n",
    "\n",
    "# Create a Pandas DataFrame from the list of dictionaries\n",
    "df = pd.DataFrame(data_list)\n",
    "\n",
    "# Print the DataFrame\n",
    "df.to_csv(\"extract_poc_disaster_assist.csv\", index=False) \n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3ef1bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8c3d40",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
